{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required library for the model development\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "import seaborn as sns\n",
    "from random import randrange, uniform\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory\n",
    "os.chdir(\"D:\\Edwisor project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv files into dataframe\n",
    "train_df=pd.read_csv(\"Train_data.csv\")\n",
    "test_df=pd.read_csv(\"Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to know number of null values present in each training csv\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to know number of null values present in each test csv\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to see the number of unique values in dataframe for object data type\n",
    "train_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to see the number of unique values in dataframe for object data type\n",
    "test_df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value analusis\n",
    "# create a dataframe to check the missing value count\n",
    "miss_val1=pd.DataFrame(train_df.isnull().sum()).reset_index()\n",
    "miss_val2=pd.DataFrame(test_df.isnull().sum()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['phone number'] = train_df['phone number'].str.replace('-','')\n",
    "test_df['phone number'] = test_df['phone number'].str.replace('-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['phone number']  = train_df['phone number'].astype('int')\n",
    "test_df['phone number']  = test_df['phone number'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot o visualize the number of ouliers\n",
    "num_df=train_df._get_numeric_data()\n",
    "for i in num_df.columns:\n",
    "    train_df.boxplot(column=i,by='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the object datatype tp categorical variable\n",
    "def ObjToCat(df):\n",
    "    lis=[]\n",
    "    for i in range(0,df.shape[1]):\n",
    "        if (df.iloc[:,i].dtype=='object'):\n",
    "            df.iloc[:,i]=pd.Categorical(df.iloc[:,i])\n",
    "            df.iloc[:,i]=df.iloc[:,i].cat.codes\n",
    "            df.iloc[:,i]=df.iloc[:,i].round()\n",
    "            df.iloc[:,i]=df.iloc[:,i].astype('object')\n",
    "            lis.append(df.columns[i])\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis1= ObjToCat(train_df)\n",
    "lis2= ObjToCat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df=train_df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to plot the histogram for all the numeric variables\n",
    "for i, col in enumerate(num_df.columns):\n",
    "    plt.figure(i)\n",
    "    sns.distplot(num_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "##### Plot the correlatuion plot for all the numeric data variab;es\n",
    "f,ax=plt.subplots(figsize=[15,12])\n",
    "test_corr_data=num_df.corr()\n",
    "train_corr_data=num_df.corr()\n",
    "sns.heatmap(test_corr_data,mask=np.zeros_like(test_corr_data,dtype=np.bool),cmap=sns.diverging_palette(220,10,as_cmap=True),\n",
    "           square=True,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the chi-square test of independence on object data variable\n",
    "cat_names=[\"state\",\"international plan\", \"voice mail plan\"]\n",
    "for i in cat_names:\n",
    "    print(i)\n",
    "    chi2, p, dof, exp=chi2_contingency(pd.crosstab(train_df['Churn'],train_df[i]))\n",
    "    chi2, p, dof, exp=chi2_contingency(pd.crosstab(test_df['Churn'],train_df[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df=train_df.drop(['state', 'area code', 'phone number'],axis=1)\n",
    "test_df=test_df.drop(['state', 'area code', 'phone number','total day minutes',\n",
    "                               'total eve minutes','total night minutes','total intl minutes'],axis=1)\n",
    "train_df=train_df.drop(['state', 'area code', 'phone number','total day minutes',\n",
    "                               'total eve minutes','total night minutes','total intl minutes'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train_df.select_dtypes([np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "# As most of the data ser are skewed let's perform the normalization\n",
    "for i in new_df.columns:\n",
    "    print(i)\n",
    "    train_df[i]=(train_df[i]-min(train_df[i]))/(max(train_df[i])-min(train_df[i]))\n",
    "    test_df[i]=(test_df[i]-min(test_df[i]))/(max(test_df[i])-min(test_df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data frame as motst of the data set are same and also variable to perform the analysis are also same0\n",
    "cust_df=pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace target categories with Yes or No\n",
    "cust_df['Churn'] = cust_df['Churn'].replace(0, 'No')\n",
    "cust_df['Churn'] = cust_df['Churn'].replace(1, 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data in train and test\n",
    "X = cust_df.values[:, 0:13]\n",
    "Y = cust_df.values[:,13]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print graphical confusion matrix representation\n",
    "def conf(algo_name,X_test, y_test):\n",
    "    y_pred = algo_name.predict(X_test)\n",
    "    forest_cm = metrics.confusion_matrix(y_pred, y_test)\n",
    "    sns.heatmap(forest_cm, annot=True, fmt='.2f',xticklabels = [\"0\", \"1\"] , yticklabels = [\"0\", \"1\"] )\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.title(str(algo_name)[0:str(algo_name).find('(')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the accuracy and False negative rate \n",
    "def confuMatrix(act, pre):\n",
    "    CM = pd.crosstab(act, pre)\n",
    "    print(CM)\n",
    "\n",
    "    #let us save TP, TN, FP, FN\n",
    "    TN = CM.iloc[0,0]\n",
    "    FN = CM.iloc[1,0]\n",
    "    TP = CM.iloc[1,1]\n",
    "    FP = CM.iloc[0,1]\n",
    "\n",
    "    #check accuracy of model\n",
    "    print(((TP+TN)*100)/(TP+TN+FP+FN))\n",
    "\n",
    "    #False Negative rate \n",
    "    print (FN*100/(FN+TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model development\n",
    "# Decision tree Classifier Model development\n",
    "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, Y_train)\n",
    "#predict new test cases\n",
    "C50_Predictions = C50_model.predict(X_test)\n",
    "print(classification_report(Y_test, C50_Predictions))\n",
    "confuMatrix(Y_test,C50_Predictions)\n",
    "conf(C50_model,X_test, Y_test)\n",
    "# Accuracy 92.6\n",
    "# FNR 24.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier model development\n",
    "RF_model = RandomForestClassifier(n_estimators = 50).fit(X_train, Y_train)\n",
    "#predict new test cases\n",
    "RF_Predictions = RF_model.predict(X_test)\n",
    "print(classification_report(Y_test, RF_Predictions))\n",
    "conf(RF_model,X_test, Y_test)\n",
    "confuMatrix(Y_test,RF_Predictions)\n",
    "# Accuracy 94\n",
    "# FNR 26.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to print important parameter percentage share\n",
    "for name, importance in zip(cust_df.columns, RF_model.feature_importances_):\n",
    "     print(name, \"=\", importance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model.\n",
    "#replace target categories with Yes or No\n",
    "cust_df['Churn'] = cust_df['Churn'].replace('No', 0)\n",
    "cust_df['Churn'] = cust_df['Churn'].replace('Yes', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create logistic data. Save target variable first\n",
    "cust_df_logit = pd.DataFrame(cust_df['Churn'])\n",
    "#Add continous variables\n",
    "cust_df_logit = cust_df_logit.join(cust_df[new_df.columns])\n",
    "##Create dummies for categorical variables\n",
    "cat_names=[\"international plan\", \"voice mail plan\"]\n",
    "for i in cat_names:\n",
    "    temp = pd.get_dummies(cust_df[i], prefix = i)\n",
    "    cust_df_logit = cust_df_logit.join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_Index = np.random.rand(len(cust_df_logit)) < 0.8\n",
    "train = cust_df_logit[Sample_Index]\n",
    "test = cust_df_logit[~Sample_Index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select column indexes for independent variables\n",
    "train_cols = train.columns[1:15]\n",
    "logit = sm.Logit(train['Churn'], train[train_cols]).fit()\n",
    "logit.summary2()\n",
    "#Predict test data\n",
    "test['Actual_prob'] = logit.predict(test[train_cols])\n",
    "test['ActualVal'] = 1\n",
    "test.loc[test.Actual_prob < 0.5, 'ActualVal'] = 0\n",
    "#Build confusion matrix\n",
    "print(confuMatrix(test['Churn'],test['ActualVal']))\n",
    "print(classification_report(test['Churn'], test['ActualVal']))\n",
    "## Accuracy 86.85770750988142\n",
    "## FNR      73.75886524822695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_cm=metrics.confusion_matrix(test['Churn'],test['ActualVal'])\n",
    "sns.heatmap(forest_cm, annot=True, fmt='.2f',xticklabels = [\"0\", \"1\"] , yticklabels = [\"0\", \"1\"] )\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.title(str(logit)[0:str(logit).find('(')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN prediction\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 3).fit(X_train, Y_train)\n",
    "# Predict the test cases\n",
    "KNN_Predictions = KNN_model.predict(X_test)\n",
    "confuMatrix(Y_test,KNN_Predictions)\n",
    "print(classification_report(Y_test, KNN_Predictions))\n",
    "conf(KNN_model,X_test,Y_test)\n",
    "## Accuracy 88.0\n",
    "## FNR 65.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes module\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Naive Bayes implementation\n",
    "NB_model = GaussianNB().fit(X_train, Y_train)\n",
    "# Predict the test cases\n",
    "NB_Predictions = NB_model.predict(X_test)\n",
    "confuMatrix(Y_test,NB_Predictions)\n",
    "print(classification_report(Y_test, NB_Predictions))\n",
    "conf(NB_model,X_test,Y_test)\n",
    "## Accuracy 88.9\n",
    "## FNR 65.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
